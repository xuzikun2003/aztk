{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "from numba import cuda, vectorize, jit\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if CUDA is available\n",
    "If it is not available, it could be one of two reasons:\n",
    "- you do not have a GPU enabled VM\n",
    "- you do not have the correct docker image (you should use the aztk/python:spark2.2.0-python3.6.2-gpu image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "if not cuda.is_available():\n",
    "    print(\"CUDA is not available. Please select a GPU enabled VM.\")\n",
    "else:\n",
    "    print(\"CUDA is available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create my CPU function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cpu_pow(a, b):\n",
    "    return a ** b\n",
    "\n",
    "def cpu_work(vec_size):\n",
    "    #vec_size = 100000000 is a good number to show the diff\n",
    "\n",
    "    a = b = np.array(np.random.sample(vec_size), dtype=np.float32)\n",
    "    c = np.zeros(vec_size, dtype=np.float32)\n",
    "\n",
    "    c = cpu_pow(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the same function, using numba to utilize GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import vectorize\n",
    "\n",
    "@vectorize(['float32(float32, float32)'], target='cuda')\n",
    "def gpu_pow(a, b):\n",
    "    return a ** b\n",
    "\n",
    "def gpu_work(vec_size):\n",
    "    #vec_size = 100000000 is a good number to show the diff\n",
    "\n",
    "    a = b = np.array(np.random.sample(vec_size), dtype=np.float32)\n",
    "    c = np.zeros(vec_size, dtype=np.float32)\n",
    "\n",
    "    c = gpu_pow(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare on single node\n",
    "On the master node, lets run the `gpu_work` against the `cpu_work` function. We will see considerable speed up using GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170 ms ± 23.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gpu_work(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "853 ms ± 1.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "cpu_work(10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare across the Spark Cluster\n",
    "Lets run the same computation, but in parallel across the Spark cluster. Once again, we will see considerable speedup when using GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitions 12\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(list([10000000]*100))\n",
    "print(\"Partitions\", rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.56 s ± 112 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "res = rdd.map(lambda x: gpu_work(x))\n",
    "res.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.5 s ± 47.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "res = rdd.map(lambda x: cpu_work(x))\n",
    "res.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
